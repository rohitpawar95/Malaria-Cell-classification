{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Necessary Libraries. Here I will be using Keras library for making classifier. We will also requires numpy and Image for making image to array imlementation. We will be using sequential model here in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classifier in Keras.ipynb  Parasitized  Uninfected\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepearaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preperation: We will make data and labels list where data will be image to array implementatation which contaions RGB values of each image. and label will be class of cells here I will be taking 0 and 1 for two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "Parasitized=os.listdir(\"Parasitized\")\n",
    "for a in Parasitized:\n",
    "    try:\n",
    "        imag=cv2.imread(\"Parasitized/\"+a)\n",
    "        img_from_ar = Image.fromarray(imag, 'RGB')\n",
    "        resized_image = img_from_ar.resize((50, 50))\n",
    "        data.append(np.array(resized_image))\n",
    "        labels.append(0)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "Uninfected=os.listdir(\"Uninfected\")\n",
    "for b in Uninfected:\n",
    "    try:\n",
    "        imag=cv2.imread(\"Uninfected/\"+b)\n",
    "        img_from_ar = Image.fromarray(imag, 'RGB')\n",
    "        resized_image = img_from_ar.resize((50, 50))\n",
    "        data.append(np.array(resized_image))\n",
    "        labels.append(1)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cells=np.array(data)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and Loading the data we prepared so next time we can load it from saved .npy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Cells\",Cells)\n",
    "np.save(\"labels\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cells=np.load(\"Cells.npy\")\n",
    "labels=np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do Train/Test Split of data and labels that prepared in early section. Classes are defined as the unique labels in the data. Here it will be 2 as Parasitized:0 and Uninfected:1, here 0 and 1 are the mapping in labels for these two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.arange(Cells.shape[0])\n",
    "np.random.shuffle(s)\n",
    "Cells=Cells[s]\n",
    "labels=labels[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=len(np.unique(labels))\n",
    "len_data=len(Cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,x_test)=Cells[(int)(0.1*len_data):],Cells[:(int)(0.1*len_data)]\n",
    "x_train = x_train.astype('float32')/255 # As we are working on image data we are normalizing data by divinding 255.\n",
    "x_test = x_test.astype('float32')/255\n",
    "train_len=len(x_train)\n",
    "test_len=len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train,y_test)=labels[(int)(0.1*len_data):],labels[:(int)(0.1*len_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the problem has two classes so last output layer of neural network will have 2 neurons one for each class, One hot encoding will help us to change labels in binary format.\n",
    "example:\n",
    "    2 can be represented as [1 0] if output layer has 2 neurons and [0 0 1 0] if output has 4 neurons/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing One hot encoding as classifier has multiple classes\n",
    "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test=keras.utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sequential Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will be using Relu{max(0,z)}, You can try tanh/sigmoid/Leaky Relu for finding performance on various activation functions.Our output layer will be softmax activation rather than sigmoid as we have more than one class to classify. softmax activation calculates e^value/sum(all_values_in_axis[0 or 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rohitp/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1152500   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 1,164,046\n",
      "Trainable params: 1,164,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating sequential model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model with loss as categorical_crossentropy and using adam optimizer you can test result by trying RMSProp as well as Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rohitp/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/rohitp/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# compile the model with loss as categorical_crossentropy and using adam optimizer you can test result by trying RMSProp as well as Momentum\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24803/24803 [==============================] - 42s - loss: 0.4104 - acc: 0.8007    \n",
      "Epoch 2/20\n",
      "24803/24803 [==============================] - 40s - loss: 0.1561 - acc: 0.9495    \n",
      "Epoch 3/20\n",
      "24803/24803 [==============================] - 40s - loss: 0.1405 - acc: 0.9542    \n",
      "Epoch 4/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.1289 - acc: 0.9565    \n",
      "Epoch 5/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.1194 - acc: 0.9597    \n",
      "Epoch 6/20\n",
      "24803/24803 [==============================] - 40s - loss: 0.1095 - acc: 0.9621    \n",
      "Epoch 7/20\n",
      "24803/24803 [==============================] - 40s - loss: 0.1009 - acc: 0.9638    \n",
      "Epoch 8/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0917 - acc: 0.9675    \n",
      "Epoch 9/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0822 - acc: 0.9700    \n",
      "Epoch 10/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0767 - acc: 0.9722    \n",
      "Epoch 11/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0641 - acc: 0.9766    \n",
      "Epoch 12/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0568 - acc: 0.9797    \n",
      "Epoch 13/20\n",
      "24803/24803 [==============================] - 40s - loss: 0.0477 - acc: 0.9831    \n",
      "Epoch 14/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0418 - acc: 0.9853    \n",
      "Epoch 15/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0365 - acc: 0.9869    \n",
      "Epoch 16/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0304 - acc: 0.9896    \n",
      "Epoch 17/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0292 - acc: 0.9906    \n",
      "Epoch 18/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0225 - acc: 0.9922    \n",
      "Epoch 19/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0221 - acc: 0.9929    \n",
      "Epoch 20/20\n",
      "24803/24803 [==============================] - 41s - loss: 0.0220 - acc: 0.9924    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ebfc0e710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with min batch size as 50[can tune batch size to some factor of 2^power ] \n",
    "model.fit(x_train,y_train,batch_size=50,epochs=20,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the accuracy on Test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720/2755 [============================>.] - ETA: 0s\n",
      " Test accuracy: 0.949183303085\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('\\n', 'Test_Accuracy:-', accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('cells.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of Model in simple application using tkinter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "def convert_to_array(img):\n",
    "    im = cv2.imread(img)\n",
    "    img_ = Image.fromarray(im, 'RGB')\n",
    "    image = img_.resize((50, 50))\n",
    "    return np.array(image)\n",
    "def get_cell_name(label):\n",
    "    if label==0:\n",
    "        return \"Paracitized\"\n",
    "    if label==1:\n",
    "        return \"Uninfected\"\n",
    "def predict_cell(file):\n",
    "    model = load_model('cells.h5')\n",
    "    print(\"Predicting Type of Cell Image.................................\")\n",
    "    ar=convert_to_array(file)\n",
    "    ar=ar/255\n",
    "    label=1\n",
    "    a=[]\n",
    "    a.append(ar)\n",
    "    a=np.array(a)\n",
    "    score=model.predict(a,verbose=1)\n",
    "    print(score)\n",
    "    label_index=np.argmax(score)\n",
    "    print(label_index)\n",
    "    acc=np.max(score)\n",
    "    Cell=get_cell_name(label_index)\n",
    "    return Cell,\"The predicted Cell is a \"+Cell+\" with accuracy =    \"+str(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rohitp/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/rohitp/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/rohitp/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Predicting Type of Cell Image.................................\n",
      "1/1 [==============================] - 0s\n",
      "[[ 0.97249401  0.02750594]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Frame, Tk, BOTH, Text, Menu, END\n",
    "from tkinter import filedialog \n",
    "from tkinter import messagebox as mbox\n",
    "\n",
    "class Example(Frame):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()   \n",
    "\n",
    "        self.initUI()\n",
    "\n",
    "\n",
    "    def initUI(self):\n",
    "\n",
    "        self.master.title(\"File dialog\")\n",
    "        self.pack(fill=BOTH, expand=1)\n",
    "\n",
    "        menubar = Menu(self.master)\n",
    "        self.master.config(menu=menubar)\n",
    "\n",
    "        fileMenu = Menu(menubar)\n",
    "        fileMenu.add_command(label=\"Open\", command=self.onOpen)\n",
    "        menubar.add_cascade(label=\"File\", menu=fileMenu)        \n",
    "\n",
    "        \n",
    "\n",
    "    def onOpen(self):\n",
    "\n",
    "        ftypes = [('Image', '*.png'), ('All files', '*')]\n",
    "        dlg = filedialog.Open(self, filetypes = ftypes)\n",
    "        fl = dlg.show()\n",
    "        c,s=predict_cell(fl)\n",
    "        root = Tk()\n",
    "        T = Text(root, height=4, width=70)\n",
    "        T.pack()\n",
    "        T.insert(END, s)\n",
    "        \n",
    "\n",
    "def main():\n",
    "\n",
    "    root = Tk()\n",
    "    ex = Example()\n",
    "    root.geometry(\"100x50+100+100\")\n",
    "    root.mainloop()  \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
